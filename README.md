# Knowledge-distillation-and-teacher-student-learning-in-medical-imaging
This is the repository of **Knowledge distillation and teacher-student learning in medical imaging: comprehensive overview, pivotal role, and future directions**, the article offers a thorough review of the current state of research concerning the application of Knowledge distillation in medical imaging.

## Abstract
Knowledge Distillation (KD) is a technique to transfer the knowledge from a complex model to a simplified model. It has been widely used in natural language processing and computer vision and has achieved advanced results. Recently, the research of KD in medical image analysis has grown rapidly. The definition of knowledge has been further expanded by combining with the medical field, and its role is not limited to simplifying the model. This paper attempts to comprehensively review the development and application of KD in the medical imaging field. Specifically, we first introduce the basic principles, explain the definition of knowledge and the classical teacher-student network framework. Then, the research progress in medical image classification, segmentation, detection, reconstruction, registration, radiology report generation, privacy protection and other application scenarios is presented. In particular, the introduction of application scenarios is based on the role of KD. We summarize eight main roles of KD techniques in medical image analysis, including model compression, semi-supervised method, weakly supervised method, class balancing, etc. The performance of these roles in all application scenarios is analyzed. Finally, we discuss the challenges in this filed and propose potential solutions. KD is still in a rapid development stage in the medical imaging field, we give four potential development directions and research hotspots.


## KD in Medical image diagnosis and classification

|Paper|PDF|Code|
|---|:---:|---|
|Framing image description as a ranking task: Data, models and evaluation metrics|[PDF](https://www.ijcai.org/Proceedings/15/Papers/593.pdf)|Code|
